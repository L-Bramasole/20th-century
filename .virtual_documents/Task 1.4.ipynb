


import pandas as pd
import matplotlib
import requests
from bs4 import BeautifulSoup
from selenium import webdriver
from webdriver_manager.chrome import ChromeDriverManager






# Scraping from url
url = "https://en.wikipedia.org/wiki/Key_events_of_the_20th_century"

headers = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
    "Accept-Language": "en-US,en;q=0.9",
    "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8",
    "Referer": "https://www.google.com/",
    "DNT": "1",
    "Connection": "keep-alive",
}

response = requests.get(url, headers=headers)
response.raise_for_status()




soup = BeautifulSoup(response.text, "html.parser")


tables = soup.find_all("table", {"class": "wikitable"})


dfs = [pd.read_html(str(t))[0] for t in tables]


events_df = pd.concat(dfs, ignore_index=True)



print(len(tables))


# Start browser
driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))
driver.get("https://en.wikipedia.org/wiki/Key_events_of_the_20th_century")

# Get HTML
html = driver.page_source
driver.quit()

# Parse HTML
soup = BeautifulSoup(html, "html.parser")

# Find tables
tables = soup.find_all("table", {"class": "wikitable"})

dfs = []
for table in tables:
    df = pd.read_html(str(table))[0]
    dfs.append(df)

# Combine
events_df = pd.concat(dfs, ignore_index=True)

print(events_df.head())




